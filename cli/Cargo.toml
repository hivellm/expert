[package]
name = "expert-cli"
version = "0.2.3"
edition = "2024"
rust-version = "1.85"

[lib]
name = "expert_cli"
path = "src/lib.rs"

[[bin]]
name = "expert-cli"
path = "src/main.rs"

[dependencies]
# CLI argument parsing
clap = { version = "4.5", features = ["derive", "color", "suggestions"] }

# Python integration for training ONLY (not for inference)
pyo3 = { version = "0.22", features = ["auto-initialize"] }

# Candle ML Framework (Rust-native inference)
# CUDA support enabled via features (compile with --features cuda on Windows)
candle-core = "0.9"
candle-nn = "0.9"
candle-transformers = "0.9"
tokenizers = "0.22"
hf-hub = "0.4"

# Half-precision floats
half = "2.4"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Error handling
anyhow = "1.0"
thiserror = "2.0"

# Async runtime
tokio = { version = "1.42", features = ["full"] }

# HTTP client for LLM APIs
reqwest = { version = "0.12", features = ["json", "rustls-tls"] }

# File operations
tar = "0.4"
flate2 = "1.0"
tempfile = "3.8"

# Crypto for signing
ed25519-dalek = { version = "2.1", features = ["rand_core"] }
rand = "0.8"
sha2 = "0.10"
hex = "0.4"

# File operations
walkdir = "2.5"

# Date/time
chrono = { version = "0.4", features = ["serde"] }

# UUID generation
uuid = { version = "1.11", features = ["v4"] }

# Terminal UI
indicatif = "0.17"
console = "0.15"
colored = "2.1"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Config management
dirs = "5.0"

[dev-dependencies]
assert_cmd = "2.0"
predicates = "3.1"
tempfile = "3.13"
rand = "0.8"

[features]
default = []
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
mkl = ["candle-core/mkl", "candle-nn/mkl"]
accelerate = ["candle-core/accelerate", "candle-nn/accelerate"]

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true

# Suppress warnings during compilation
[lints.rust]
unused_variables = "allow"
dead_code = "allow"
unused_imports = "allow"
unused_mut = "allow"

# Debian package metadata
[package.metadata.deb]
maintainer = "HiveLLM Team <team@hivellm.org>"
copyright = "2025, HiveLLM Team <team@hivellm.org>"
license-file = ["../LICENSE", "4"]
extended-description = """\
Expert CLI - A command-line tool for training, packaging, and deploying expert models.
Supports routing, hot-swapping, and CUDA acceleration for high-performance inference."""
depends = "$auto, python3 (>= 3.11)"
section = "devel"
priority = "optional"
assets = [
    ["target/release/expert-cli", "usr/bin/", "755"],
    ["README.md", "usr/share/doc/expert-cli/", "644"],
    ["CHANGELOG.md", "usr/share/doc/expert-cli/", "644"],
]
