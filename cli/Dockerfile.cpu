# Multi-stage Dockerfile for HiveLLM Expert CLI (CPU only)
# Lighter image without CUDA dependencies

# Stage 1: Rust build
FROM rust:1.85-slim-bookworm AS rust-builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /build

# Copy Cargo files
COPY Cargo.toml Cargo.lock ./
COPY src ./src
COPY tests ./tests

# Build release (CPU only)
RUN cargo build --release

# Stage 2: Runtime with Python
FROM python:3.12-slim-bookworm

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy Python requirements and scripts
COPY requirements.txt ./
COPY expert_trainer.py ./
COPY scripts ./scripts

# Install Python dependencies (CPU versions)
RUN pip install --no-cache-dir -U pip setuptools wheel && \
    pip install --no-cache-dir \
    torch==2.5.1+cpu \
    -f https://download.pytorch.org/whl/torch_stable.html && \
    pip install --no-cache-dir -r requirements.txt

# Copy Rust binary from builder
COPY --from=rust-builder /build/target/release/expert-cli /usr/local/bin/expert-cli

# Create directories
RUN mkdir -p /models /experts /datasets

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/models/cache

# Default command
CMD ["expert-cli", "--help"]

# Usage:
# Build: docker build -f Dockerfile.cpu -t hivellm-expert:cpu .
# Run training: docker run -v $(pwd)/experts:/experts -v $(pwd)/models:/models hivellm-expert:cpu expert-cli train --manifest /experts/manifest.json --device cpu
# Run chat: docker run -it -v $(pwd)/models:/models hivellm-expert:cpu expert-cli chat

