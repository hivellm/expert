# Dockerfile optimized for training experts with PyTorch + CUDA
# Includes all training dependencies and utilities

FROM nvidia/cuda:12.6.0-cudnn9-devel-ubuntu22.04

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Install Python 3.12 and system dependencies
RUN apt-get update && apt-get install -y \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update && apt-get install -y \
    python3.12 \
    python3.12-dev \
    python3.12-venv \
    python3-pip \
    git \
    wget \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Create symlinks for python
RUN ln -sf /usr/bin/python3.12 /usr/bin/python3 && \
    ln -sf /usr/bin/python3 /usr/bin/python && \
    python3 -m pip install --upgrade pip setuptools wheel

# Set working directory
WORKDIR /workspace

# Copy requirements first (better caching)
COPY requirements.txt ./

# Install PyTorch with CUDA 12.6 support
RUN pip3 install --no-cache-dir \
    torch==2.5.1 \
    torchvision==0.20.1 \
    torchaudio==2.5.1 \
    --index-url https://download.pytorch.org/whl/cu124

# Install training dependencies
RUN pip3 install --no-cache-dir -r requirements.txt

# Install additional training utilities
RUN pip3 install --no-cache-dir \
    tensorboard \
    wandb \
    jupyter \
    ipykernel \
    matplotlib \
    seaborn \
    plotly

# Copy Python scripts
COPY expert_trainer.py ./
COPY scripts ./scripts

# Create directories for training artifacts
RUN mkdir -p /workspace/models \
    /workspace/datasets \
    /workspace/weights \
    /workspace/experts \
    /workspace/logs \
    /workspace/cache

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0
ENV HF_HOME=/workspace/cache/huggingface
ENV TRANSFORMERS_CACHE=/workspace/cache/transformers
ENV TORCH_HOME=/workspace/cache/torch

# Expose TensorBoard port
EXPOSE 6006

# Default command shows training help
CMD ["python3", "expert_trainer.py", "--help"]

# Usage Examples:
#
# Build:
#   docker build -f Dockerfile.train -t hivellm-expert:train .
#
# Train expert:
#   docker run --gpus all \
#     -v $(pwd)/experts:/workspace/experts \
#     -v $(pwd)/models:/workspace/models \
#     -v $(pwd)/datasets:/workspace/datasets \
#     -v $(pwd)/weights:/workspace/weights \
#     hivellm-expert:train \
#     python3 expert_trainer.py \
#       --manifest /workspace/experts/expert-neo4j/manifest.json \
#       --output /workspace/weights/neo4j \
#       --device cuda
#
# Interactive session:
#   docker run --gpus all -it \
#     -v $(pwd):/workspace \
#     hivellm-expert:train \
#     /bin/bash
#
# TensorBoard:
#   docker run --gpus all -p 6006:6006 \
#     -v $(pwd)/logs:/workspace/logs \
#     hivellm-expert:train \
#     tensorboard --logdir=/workspace/logs --host=0.0.0.0

