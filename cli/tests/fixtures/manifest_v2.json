{
  "name": "test-expert-v2",
  "version": "2.0.0",
  "schema_version": "2.0",
  "description": "Test expert for schema v2.0 with multiple models",
  "author": "Test Author",
  
  "base_models": [
    {
      "name": "Qwen3-0.6B",
      "sha256": "test_hash_0.6b",
      "quantization": "int4",
      "rope_scaling": "yarn-128k",
      "adapters": [
        {
          "type": "lora",
          "target_modules": ["q_proj", "v_proj"],
          "r": 16,
          "alpha": 16,
          "scaling": "standard",
          "dropout": 0.05,
          "path": "weights/qwen3-0.6b/adapter.safetensors",
          "size_bytes": 8388608,
          "sha256": "adapter_hash_0.6b"
        }
      ]
    },
    {
      "name": "Qwen3-1.5B",
      "sha256": "test_hash_1.5b",
      "quantization": "int4",
      "rope_scaling": "yarn-128k",
      "adapters": [
        {
          "type": "lora",
          "target_modules": ["q_proj", "v_proj", "o_proj"],
          "r": 16,
          "alpha": 16,
          "scaling": "standard",
          "dropout": 0.05,
          "path": "weights/qwen3-1.5b/adapter.safetensors",
          "size_bytes": 16777216,
          "sha256": "adapter_hash_1.5b"
        }
      ]
    }
  ],
  
  "capabilities": ["test", "multi-model"],
  
  "constraints": {
    "load_order": 5,
    "incompatible_with": [],
    "requires": []
  },
  
  "training": {
    "dataset": {
      "path": "datasets/data.jsonl"
    },
    "config": {
      "method": "sft",
      "adapter_type": "lora",
      "rank": 16,
      "alpha": 16,
      "target_modules": ["q_proj", "v_proj"],
      "epochs": 3,
      "learning_rate": 0.0003,
      "batch_size": 4,
      "gradient_accumulation_steps": 4,
      "warmup_steps": 100,
      "lr_scheduler": "cosine"
    }
  }
}

